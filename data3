# -*- coding: utf-8 -*-
# @Time    : 17-12-26 下午4:04
# @Author  : Lin
# @Email   : wujialin5@huawei.com
# @File    : features_merge.py
# @Software: PyCharm


import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.externals import joblib
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from eda1 import wea_null_pro

def features_concate(filename):
    data = pd.read_csv(filename+'.csv', parse_dates=[['create_date', 'create_hour']])
    data.rename(columns={'create_date_create_hour': 'date'}, inplace=True)

    poi = pd.read_csv('poi_header.csv')
    poi_dict = {}
    for i in range(len(poi)):
        row = list(poi.iloc[i])
        poi_dict[row[0]] = map(float, row[1:])

    sub_mat = []
    for s,e in zip(data['start_geo_id'], data['end_geo_id']):
        start = poi_dict.get(s, [0]*10)
        end = poi_dict.get(e, [0] * 10)
        sub = np.array(end)-np.array(start)
        sub_mat.append(sub)
    rank = pd.DataFrame(sub_mat).rank(method='max')*1.0/len(sub_mat)
    print rank.head()
    data = pd.concat([data, rank], axis=1)

    # july_poi = pd.merge(july, poi, how='left',
    #                     left_on=['start_geo_id'], right_on=['geo_id'])
    # july_poi = pd.merge(july_poi, poi, how='left',
    #                     left_on=['end_geo_id'], right_on=['geo_id'])
    # july_poi.drop(['geo_id_x', 'geo_id_y'], axis=1, inplace=True)
    #
    # july_poi.fillna(0, inplace=True)

    wea = pd.read_csv('weather.csv', parse_dates=['date'])
    data_poi_wea = pd.merge(data, wea, on=['date'], how='left')
    data_poi_wea.to_csv(filename+'_poi_wea.csv', index=False)

wea_null_pro()
features_concate('train_aug')
features_concate('train_july')
features_concate('test_id_aug')


def read_train(filename):
    data = pd.read_csv(filename+'_poi_wea.csv')
    return data

def model(train_x, train_y, test_x):
    alg = GradientBoostingRegressor()
    alg.fit(train_x, train_y)
    joblib.dump(alg, 'gbr.pkl')
    result = alg.predict(test_x)
    return result

def xgb_model(train_x, train_y, test_x):
    dtrain = xgb.DMatrix(train_x, label=train_y)
    dtest = xgb.DMatrix(test_x)

    params = {'booster': 'gbtree',
              # 'objective': 'binary:logistic',
              'eval_metric': 'mae',
              'max_depth': 4,
              'lambda': 10,
              'subsample': 0.75,
              'colsample_bytree': 0.75,
              'min_child_weight': 2,
              'eta': 0.025,
              'seed': 0,
              'nthread': 8,
              'silent': 1}

    watchlist = [(dtrain, 'train')]

    bst = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist)

    ypred = bst.predict(dtest)
    return ypred

def plot(data):
    plt.figure()
    sns.boxplot(data['wind_scale'], data['count'])

train_aug = read_train('train_aug')
train_july = read_train('train_july')
test_aug = read_train('test_id_aug')
print train_aug.shape
print train_july.shape
print test_aug.shape



aug_x, aug_y = train_aug.iloc[:, 4:], train_aug['count']
july_x, july_y = train_july.iloc[:, 4:], train_july['count']
test_x, test_id = test_aug.iloc[:, 4:], test_aug['test_id']


# sns.boxplot(train_aug['wind_scale'], train_aug['count'])

# cormat = train_aug.iloc[:, 3:].corr()
# sns.heatmap(cormat)
# plt.show()


result = xgb_model(july_x, july_y, aug_x)
for i,j in zip(aug_y, result):
    print i, j
print mean_absolute_error(aug_y, result)
exit(0)

train_x = pd.concat([july_x, aug_x])
train_y = pd.concat([july_y, aug_y])

ypred = xgb_model(train_x, train_y, test_x)
pd.DataFrame({'test_id': test_id, 'count':ypred}).to_csv('1.csv', index=False)






